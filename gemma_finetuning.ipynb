{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b946f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.46.0-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch<3,>=2.2 in c:\\users\\stras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bitsandbytes) (2.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\stras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\stras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\stras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch<3,>=2.2->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\stras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\stras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\stras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch<3,>=2.2->bitsandbytes) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\stras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch<3,>=2.2->bitsandbytes) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\stras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\stras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\stras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (2.1.5)\n",
      "Downloading bitsandbytes-0.46.0-py3-none-win_amd64.whl (66.5 MB)\n",
      "   ---------------------------------------- 0.0/66.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/66.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/66.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/66.5 MB 2.5 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 1.8/66.5 MB 3.0 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 2.1/66.5 MB 2.9 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 3.1/66.5 MB 3.0 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 3.7/66.5 MB 3.2 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 4.2/66.5 MB 3.0 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 5.0/66.5 MB 3.1 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 5.8/66.5 MB 3.1 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 6.3/66.5 MB 3.1 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 6.8/66.5 MB 3.0 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 7.6/66.5 MB 3.1 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 8.1/66.5 MB 3.1 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 8.7/66.5 MB 3.0 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 8.9/66.5 MB 3.0 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 10.0/66.5 MB 3.0 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 10.7/66.5 MB 3.1 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 11.3/66.5 MB 3.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 12.1/66.5 MB 3.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 12.8/66.5 MB 3.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 13.4/66.5 MB 3.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 14.2/66.5 MB 3.2 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 14.9/66.5 MB 3.2 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 16.0/66.5 MB 3.2 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 16.5/66.5 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 17.0/66.5 MB 3.2 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 17.8/66.5 MB 3.2 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 18.4/66.5 MB 3.2 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 19.1/66.5 MB 3.2 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 20.2/66.5 MB 3.3 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 21.0/66.5 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 21.5/66.5 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 22.5/66.5 MB 3.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 23.1/66.5 MB 3.3 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 23.9/66.5 MB 3.3 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 24.6/66.5 MB 3.3 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 25.4/66.5 MB 3.3 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 26.2/66.5 MB 3.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 27.3/66.5 MB 3.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 28.0/66.5 MB 3.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 28.6/66.5 MB 3.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 29.9/66.5 MB 3.4 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 30.7/66.5 MB 3.5 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 31.5/66.5 MB 3.5 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 32.8/66.5 MB 3.5 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 33.6/66.5 MB 3.5 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 34.3/66.5 MB 3.5 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 34.9/66.5 MB 3.5 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 35.1/66.5 MB 3.5 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 35.7/66.5 MB 3.5 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 36.4/66.5 MB 3.5 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 37.2/66.5 MB 3.5 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 38.0/66.5 MB 3.5 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 38.5/66.5 MB 3.5 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 39.3/66.5 MB 3.5 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 40.4/66.5 MB 3.5 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 41.2/66.5 MB 3.5 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 41.7/66.5 MB 3.5 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 41.9/66.5 MB 3.5 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 42.5/66.5 MB 3.4 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 42.7/66.5 MB 3.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 43.5/66.5 MB 3.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 43.8/66.5 MB 3.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 44.6/66.5 MB 3.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 44.6/66.5 MB 3.4 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 45.4/66.5 MB 3.3 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 45.6/66.5 MB 3.3 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 46.1/66.5 MB 3.3 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 46.4/66.5 MB 3.3 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 46.7/66.5 MB 3.3 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 47.4/66.5 MB 3.2 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 48.0/66.5 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 48.2/66.5 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 48.5/66.5 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 49.0/66.5 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 49.5/66.5 MB 3.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 49.8/66.5 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 50.6/66.5 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 50.9/66.5 MB 3.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 51.6/66.5 MB 3.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 51.6/66.5 MB 3.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 52.2/66.5 MB 3.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 52.4/66.5 MB 3.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 53.2/66.5 MB 3.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 53.5/66.5 MB 3.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 53.7/66.5 MB 3.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 54.3/66.5 MB 3.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 54.5/66.5 MB 3.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 55.1/66.5 MB 3.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 55.3/66.5 MB 3.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 55.8/66.5 MB 3.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 56.4/66.5 MB 3.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 56.6/66.5 MB 3.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 56.9/66.5 MB 3.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 57.1/66.5 MB 2.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 57.4/66.5 MB 2.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 57.7/66.5 MB 2.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 57.9/66.5 MB 2.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 58.2/66.5 MB 2.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 58.5/66.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 59.0/66.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 59.5/66.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 59.8/66.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 60.3/66.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 60.6/66.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 60.8/66.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 61.3/66.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 61.6/66.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 62.1/66.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 62.4/66.5 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 62.9/66.5 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 63.4/66.5 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 63.7/66.5 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 64.2/66.5 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 64.5/66.5 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 64.7/66.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  65.5/66.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  66.1/66.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  66.3/66.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 66.5/66.5 MB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.46.0\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes\n",
    "!pip install -q diffusers transformers accelerate peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cd8fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM, \n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c6dce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79581c2ae694b83b2329c6ccc4a92da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/33.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0e2ab72e4242e0b8743592b187909d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc11624562e84fa292f2070b1f80f417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ad23e02f3a4433a53bf1005cc4b85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stras\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\auto\\auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c62ec49d7144a49acb7913ac894906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5775604e6746098bc1e13094f04e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14514b50a4b94142990582e106e8dfb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05eeb44eaac64050b25416b52677ff32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b479d630f74e338a66286d0a9cdb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "import os\n",
    "from getpass import getpass\n",
    "import time\n",
    "\n",
    "# set HF_TOKEN environment variable\n",
    "if 'HF_TOKEN' not in os.environ:\n",
    "    os.environ['HF_TOKEN'] = getpass(\"Enter your Hugging Face token: \")\n",
    "\n",
    "model_id = \"google/gemma-2b\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\", token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\", token=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# Set padding token to the eos token if not set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load and prepare the dataset\n",
    "# Assuming you have Sumerian-Italian parallel data in CSV/TSV format\n",
    "# Format should have 'sumerian' and 'italian' columns\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Load your dataset - adjust based on actual file format\n",
    "    df = pd.read_csv(file_path, sep='\\t')  # or pd.read_csv for comma-separated\n",
    "    \n",
    "    # Ensure the dataframe has 'sumerian' and 'italian' columns\n",
    "    assert 'sumerian' in df.columns, \"Dataset must contain 'sumerian' column\"\n",
    "    assert 'italian' in df.columns, \"Dataset must contain 'italian' column\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Replace these paths with your actual data files\n",
    "train_df = load_data('path/to/train_data.csv') \n",
    "val_df = load_data('path/to/val_data.csv')\n",
    "test_df = load_data('path/to/test_data.csv')\n",
    "\n",
    "# Convert to HuggingFace datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "print(f\"Dataset loaded: {len(train_dataset)} training, {len(val_dataset)} validation, {len(test_dataset)} test examples\")\n",
    "\n",
    "# Configure the tokenizer for translation task\n",
    "tokenizer.src_lang = \"sumerian\"\n",
    "tokenizer.tgt_lang = \"english\"\n",
    "\n",
    "# 3. Preprocess the data\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the Sumerian texts\n",
    "    inputs = [text for text in examples[\"sumerian\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    # Tokenize the Italian translations\n",
    "    targets = [text for text in examples[\"italian\"]]\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    # Replace padding token id with -100 so it's ignored in loss calculation\n",
    "    for i in range(len(model_inputs[\"labels\"])):\n",
    "        model_inputs[\"labels\"][i] = [\n",
    "            -100 if token == tokenizer.pad_token_id else token \n",
    "            for token in model_inputs[\"labels\"][i]\n",
    "        ]\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing to all datasets\n",
    "tokenized_datasets = dataset_dict.map(preprocess_function, batched=True)\n",
    "\n",
    "# 4. Configure training\n",
    "batch_size = 16  # Adjust based on your GPU memory\n",
    "output_dir = \"./gemma-sumerian-italian\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available(),  # Use mixed precision if available\n",
    "    push_to_hub=False,  # Set to True if you want to upload to HF Hub\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "# 5. Define data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=\"max_length\"\n",
    ")\n",
    "\n",
    "# 6. Define evaluation metric (BLEU)\n",
    "bleu = load(\"sacrebleu\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    \n",
    "    # Replace -100 with pad token id\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Decode predictions and labels\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Postprocess to compute BLEU properly\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]  # BLEU expects a list of lists\n",
    "    \n",
    "    result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [len(pred.split()) for pred in decoded_preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "# 7. Initialize trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# 8. Train the model\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# 9. Save the model\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")\n",
    "\n",
    "# 10. Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(f\"Test results: {test_results}\")\n",
    "\n",
    "# 11. Translation examples\n",
    "def translate(sumerian_text):\n",
    "    inputs = tokenizer(sumerian_text, return_tensors=\"pt\", padding=True).to(device)\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=max_target_length,\n",
    "        num_beams=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translation\n",
    "\n",
    "# Test translation on a few examples\n",
    "test_examples = test_dataset.select(range(5))\n",
    "print(\"\\nTranslation examples:\")\n",
    "for example in test_examples:\n",
    "    sumerian = example[\"sumerian\"]\n",
    "    actual_italian = example[\"italian\"]\n",
    "    predicted_italian = translate(sumerian)\n",
    "    print(f\"Sumerian:          {sumerian}\")\n",
    "    print(f\"Actual Italian:    {actual_italian}\")\n",
    "    print(f\"Predicted Italian: {predicted_italian}\")\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
